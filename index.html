<!DOCTYPE html>
<html>
<head>
    <title>TTS Accent Comparison</title>
    <style>
        body {
            font-family: Times New Roman, serif;
            margin: 0;
            padding: 0;
        }
        header {
            padding: 20px;
            text-align: left;
        }
        hr {
            margin: 20px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: center;
        }
        th {
            background-color: #f2f2f2;
        }
        .highlight {
            background-color: lightgreen;
        }
        .experiment-section {
            display: none;
        }
    </style>
</head>
<body>
    <header>
        <h1>Experimentos - Qualificação </h1>
        <h2>Um sintetizador de fala Zero-Shot Multi-Speaker para as diferentes variações linguísticas do português brasileiro - Gustavo Evangelista Araújo</h2>
        <hr>
        <h2>Comparação entre sistemas</h2>
        <p><b>YourTTS (CASANOVA <i>et al</i>, 2021):</b> <i>YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS. Our method builds upon the VITS model and adds several novel modifications for zero-shot multi-speaker and multilingual training. We achieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and results comparable to SOTA in zero-shot voice conversion on the VCTK dataset.</i> <a href="https://arxiv.org/abs/2112.02418">Link</a></p>
        <p><b>SYNTACC (NGUYEN <i>et al</i>, 2023):</b> <i>The method works by decomposing each weight matrix into a shared component and an accent-dependent component, with the former being initialized by the pretrained multi-speaker TTS model and the latter being factorized into vectors using rank-1 matrices to reduce the number of training parameters per accent. This weight factorization method proves to be effective in fine-tuning the SYNTACC on multi-accent data sets in a low-resource condition.</i> <a href="https://ieeexplore.ieee.org/document/10096431">Link</a></p>
        <hr>
    </header>

    <select id="experimentSelect" onchange="showExperiment()">
        <option value="">Selecione o experimento</option>
        <option value="experiment1">Experimento 1: Transferência de sotaque</option>
        <option value="experiment2">Experimento 2: Qualidade geral</option>
        <option value="experiment3">Experimento 3: Prova de conceito</option>
    </select>

    <div id="experiment1" class="experiment-section">
        <h2>Experiment 1: Transferência de sotaque</h2>
        Conclusões: 
        <ul>
            <li>brsp>brpr e brpb>brpr: Estes foram alguns dos casos com síntese mais natural, onde é perceptível a mudança de prosódia tanto do sotaque de São Paulo (SP) quanto da Paraíba (PB). Foi observado que nos dados de treinamento há apenas uma falante com gravação e dicção excelentes, porém com um sotaque mais 'neutro'.</li>
            <li>brpb>brpb e brsp>brsp: Parece que o modelo SYNTACC consegue sintetizar melhor o sotaque do locutor para o qual foi treinado.</li>
            <li>brpb>brce: Neste caso, o YourTTS não conseguiu sintetizar algo inteligível, enquanto que o SYNTACC produziu algumas palavras compreensíveis. Nos dados de treinamento, há apenas um locutor com sotaque que parece ser do Ceará, mas com um ruído constante de fundo.</li>
            <li>brpb>alemanha: Fica evidente a mudança de prosódia nos dois modelos, mas ainda mais evidente no SYNTACC, passando a impressão de ser um estrangeiro falando.</li>
            <li>brpb>portugal: A mudança de prosódia é evidente nos dois modelos, mas não fica claro qual dos dois é melhor.</li>
        </ul>
        <p><strong>Configurações</strong></p>
         <ul>
            <li>Dataset Mupe-v1
                <ul>
                    <li>Horas: ~90h</li>
                    <li>Falantes: 86</li>
                    <li>Variações linguísticas regionais: 11</li>
                    <li>Variações linguísticas internacionais: 2</li>
                </ul>
            </li>
            <li>Treinamento:</li>
                 <ul>
                    <li>YourTTS: 485.000 steps</li>
                    <li>SYNTACC: 295.000 steps</li>
                    <li>Sample_rate: 16kHz</li>
                    <li>checkpoint: cml_tts_dataset <a href="https://drive.usercontent.google.com/download?id=1yDCSJ1pFZQTHhL09GMbOrdjcPULApa0p&authuser=2">Link</a></p> </li>
                 </ul>
        </ul>
        <div id="audioTable1"></div>
    </div>

    <div id="experiment2" class="experiment-section">
        <h2>Experiment 2: Qualidade geral</h2>
        <p><strong>Configurações</strong></p>
         <ul>
            <li>Dataset Mupe-v1
                <ul>
                    <li>Horas: ~90h</li>
                    <li>Falantes: 86</li>
                    <li>Variações linguísticas regionais: 11</li>
                    <li>Variações linguísticas internacionais: 2</li>
                </ul>
            </li>
            <li>Treinamento:</li>
                 <ul>
                    <li>YourTTS: 505.000 steps</li>
                    <li>SYNTACC: 295.000 steps</li>
                    <li>Sample_rate: 16kHz</li>
                    <li>checkpoint: cml_tts_dataset <a href="https://drive.usercontent.google.com/download?id=1yDCSJ1pFZQTHhL09GMbOrdjcPULApa0p&authuser=2">Link</a></p> </li>
                 </ul>
        </ul>
        <div id="audioTable2"></div>
    </div>

    <div id="experiment3" class="experiment-section">
        <h2>Experiment 3: Prova de conceito</h2>
        <p><strong>Configurações</strong></p>
         <ul>
            <li>Dataset Mupe-v1 - Um falante por variação linguística
                <ul>
                    <li>Horas: ~12h</li>
                    <li>Falantes: 12</li>
                    <li>Variações linguísticas regionais: 11</li>
                    <li>Variações linguísticas internacionais: 2</li>
                </ul>
            </li>
            <li>Treinamento:</li>
                 <ul>
                    <li>SYNTACC: 485.000 steps</li>
                    <li>Sample_rate: 16kHz</li>
                    <li>checkpoint: Fine-tunning do modelo apresentado no experimento 1/2
                 </ul>
        </ul>
        <div id="audioTable3"></div>
    </div>

    <script>
        const accentsExperiment1 = ['bral', 'brpb', 'brsp'];
        const accentTransfers = ['bral', 'brba', 'brce', 'brgo', 'brmg', 'brpb', 'brpe', 'brportugal', 'brpr', 'brrj', 'brrs', 'brsp', 'bralemanha'];
        const accentsExperiment2 = ['bral', 'brba', 'brce', 'brgo', 'brmg', 'brpb', 'brpe', 'brportugal', 'brpr', 'brrj', 'brrs', 'brsp', 'bralemanha'];
        const accentsExperiment3 = ['bral', 'brpb', 'brsp'];

        // Highlight rows for each accent in Experiment 1
        const highlightRowsExperiment1 = {
            'bral': [1, 3, 9, 12, 13],
            'brpb': [6, 8, 9, 12, 13],
            'brsp': [1, 3, 9, 12, 13]
        };

        // Highlight rows for each accent in Experiment 2
        const highlightRowsExperiment2 = {
            'bral': [4,7,9,12,24],
            'brba': [3,16,19,22],
            'brce': [13,19,20,23],
            'brgo': [12,13,27,26,28],
            'brmg': [11,20,24,26],
            'brpb': [23,28,29,20,18],
            'brpe': [06,11,12,20,23,25],
            'brportugal': [11,22,24,28,29],
            'brpr': [11,15,17,21,23,29],
            'brrj': [],
            'brrs': [],
            'brsp': [],
            'bralemanha': []
        };

        const highlightRowsExperiment3 = {
            'bral': [1, 3, 9, 12, 13],
            'brpb': [6, 8, 9, 12, 13],
            'brsp': [1, 3, 9, 12, 13]
        };

        function createAudioTable1() {
            const table = document.createElement('table');
            table.innerHTML = `
                <tr>
                    <th>Speaker Sample</th>
                    <th>YourTTS</th>
                    <th>SYNTACC</th>
                </tr>
            `;

            accentsExperiment1.forEach(accent => {
                const groundTruthRow = table.insertRow();
                const gtCell = groundTruthRow.insertCell();
                gtCell.rowSpan = accentTransfers.length+1;
                const groundTruthPath = `experimento1/yourtts/${accent}/ground_truth.wav`;
                console.log(`Ground Truth Path: ${groundTruthPath}`);
                gtCell.innerHTML = `Ground Truth (Accent: ${accent}):<br>
                    <audio controls>
                        <source src="${groundTruthPath}" type="audio/wav">
                    </audio><br><span>${groundTruthPath}</span><br><i>Transcription: ${accent}</i>`;

                accentTransfers.forEach((transfer, index) => {
                    const row = table.insertRow();
                    if (highlightRowsExperiment1[accent].includes(index)) {
                        row.classList.add('highlight');
                    }

                    const yourttsPath = `experimento1/yourtts/${accent}/${accent}to${transfer}-yourtts-505Ksteps.wav`;
                    console.log(`YourTTS Path: ${yourttsPath}`);
                    const yourttsCell = row.insertCell();
                    yourttsCell.innerHTML = `YourTTS ${index + 1}:<br>
                        <audio controls>
                            <source src="${yourttsPath}" type="audio/wav">
                        </audio><br><span>${yourttsPath}</span><br>`;

                    const syntaccPath = `experimento1/syntacc/${accent}/${accent}to${transfer}-syntacc-295Ksteps.wav`;
                    console.log(`SYNTACC Path: ${syntaccPath}`);
                    const syntaccCell = row.insertCell();
                    syntaccCell.innerHTML = `SYNTACC ${index + 1}:<br>
                        <audio controls>
                            <source src="${syntaccPath}" type="audio/wav">
                        </audio><br><span>${syntaccPath}</span><br>`;
                });
            });

            document.getElementById('audioTable1').appendChild(table);
        }

        function createAudioTable2() {
            const table = document.createElement('table');
            table.innerHTML = `
                <tr>
                    <th>Ground Truth</th>
                    <th>YourTTS</th>
                    <th>SYNTACC</th>
                </tr>
            `;

            accentsExperiment2.forEach(accent => {
                for (let i = 0; i < 30; i++) {
                    const row = table.insertRow();
                    if (highlightRowsExperiment2[accent].includes(i)) {
                        row.classList.add('highlight');
                    }

                    const groundTruthPath = `experimento2/${accent}/${accent}-${i}-gt.wav`;
                    const groundTruthCell = row.insertCell();
                    groundTruthCell.innerHTML = `Accent: ${accent}, Sample ${i}<br>
                        <audio controls>
                            <source src="${groundTruthPath}" type="audio/wav">
                        </audio><br><span>${groundTruthPath}</span><br>`;

                    const yourttsPath = `experimento2/${accent}/${accent}-${i}-yourtts-505Ksteps.wav`;
                    const yourttsCell = row.insertCell();
                    yourttsCell.innerHTML = `Accent: ${accent}, Sample ${i}<br>
                        <audio controls>
                            <source src="${yourttsPath}" type="audio/wav">
                        </audio><br><span>${yourttsPath}</span><br>`;

                    const syntaccPath = `experimento2/${accent}/${accent}-${i}-syntacc-295Ksteps.wav`;
                    const syntaccCell = row.insertCell();
                    syntaccCell.innerHTML = `Accent: ${accent}, Sample ${i}<br>
                        <audio controls>
                            <source src="${syntaccPath}" type="audio/wav">
                        </audio><br><span>${syntaccPath}</span><br>`;
                }
            });

            document.getElementById('audioTable2').appendChild(table);
        }

        function createAudioTable3() {
            const table = document.createElement('table');
            table.innerHTML = `
                <tr>
                    <th>Speaker Sample</th>
                    <th>SYNTACC</th>
                </tr>
            `;

            accentsExperiment3.forEach(accent => {
                const groundTruthRow = table.insertRow();
                const gtCell = groundTruthRow.insertCell();
                gtCell.rowSpan = accentTransfers.length+1;
                const groundTruthPath = `experimento3/syntacc/${accent}/ground_truth.wav`;
                console.log(`Ground Truth Path: ${groundTruthPath}`);
                gtCell.innerHTML = `Ground Truth (Accent: ${accent}):<br>
                    <audio controls>
                        <source src="${groundTruthPath}" type="audio/wav">
                    </audio><br><span>${groundTruthPath}</span><br><i>Transcription: ${accent}</i>`;

                accentTransfers.forEach((transfer, index) => {
                    const row = table.insertRow();
                    if (highlightRowsExperiment3[accent].includes(index)) {
                        row.classList.add('highlight');
                    }

                    const syntaccPath = `experimento3/syntacc/${accent}/${accent}to${transfer}-syntacc-OneByAccent-485Ksteps.wav`;
                    console.log(`SYNTACC Path: ${syntaccPath}`);
                    const syntaccCell = row.insertCell();
                    syntaccCell.innerHTML = `SYNTACC ${index + 1}:<br>
                        <audio controls>
                            <source src="${syntaccPath}" type="audio/wav">
                        </audio><br><span>${syntaccPath}</span><br>`;
                });
            });

            document.getElementById('audioTable3').appendChild(table);
        }
        
        function showExperiment() {
            const selectedExperiment = document.getElementById('experimentSelect').value;
            document.querySelectorAll('.experiment-section').forEach(section => {
                section.style.display = 'none';
            });
            if (selectedExperiment) {
                document.getElementById(selectedExperiment).style.display = 'block';
            }
            if (selectedExperiment === 'experiment1' && !document.getElementById('audioTable1').hasChildNodes()) {
                createAudioTable1();
            } else if (selectedExperiment === 'experiment2' && !document.getElementById('audioTable2').hasChildNodes()) {
                createAudioTable2();
            } else if (selectedExperiment === 'experiment3' && !document.getElementById('audioTable3').hasChildNodes()) {
                createAudioTable3();
            }
        }
    </script>
</body>
</html>
